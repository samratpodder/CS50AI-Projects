I started with one hidden layer and found that accuracy was almost 40% so i added a couple of layers and noticed that accuracy changed up drastically. then i noticed a pattern that if there is random increase and decrease in number of neurons in between the hidden layers then there is a decrease in accuracy. so i made a pattern of increase first and then decrease to some number of neuron greater than number of neurons in output layer. then i started changing the dropout amount to get a good value of accuracy in test data set. the sweet spot was in and around 0.4 to 0.5 and i choose to go with 0.4 because it gave much consistent results. i also noticed that making a network very deep will not help to a great extent but it definately takes more computational power.